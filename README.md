# Kinesis as an Event Collector

Kinesis can be used as an Event Collector Service.
The clients, for example mobile devices, push events directly into a Kinesis Stream.

In this exercise the incoming events are generated by reading them from a file or creating them randomly.


## Naive Python

Start with an implementation as simple as possible.

For the consumer use a small python script which reads from a downloaded file and writes line-by-line after being converted to an *event*.
Write the data into a *Kinesis* stream.

The consumer would be another simple python script.
Pull the events from the Kinesis stream.
Tag all events seen within a single minute with the same key value.
Next steps are a `groupByKey`, emit value from groupBy when different key value arrives in stream and write result to S3.

In case events should be counted by type and minute a composite key can be used. In Python use a tuple `((“usa”, “201608211700”), 1)`.

The events per minute per worker would be on S3 in real-time.

This implementation is fine to get something working with Kinesis.
Obviously it is of no use for a real-world application.


### Design

Simplest design consists of two modules.

1. The `producer`, which reads the data from the file sequentially.
Transforms CSV raw data into an event.
Creates a batch of event data.
Then pushes a batch into the Kinesis stream.

2. A `consumer`, which polls from the Kinesis stream.
Aggregates the event data.
And writes the result into persistent storage.


### Setup
use `virtualenvwrapper` and create a *virtual environment* for python.
```
mkvirtualenv streams
```

install the packages into the *virtual environment*
```
pip install -r requirements.txt
```


### Run

producer can either generate infinite stream of random events or finite stream of events read from a file.

to pick one of the two change `inject.configure()` in `producer.py`.

```
python producer.py
```
